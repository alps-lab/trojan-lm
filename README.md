# NLPSec
Backdoor Attacks against Language Models (To appear in 2021 6th IEEE European Symposium on Security and Privacy)

## Requirements

Pytorch

Transformers

Stanza

## Folder Structure

toxic_comments: Toxic Comment Classification

question_answering: Question Answering

text_generation: Text Generation with GPT-2

text_infilling: scripts about Context-Aware Generative Model

## Context-Aware Generation Model (Checkpoints)

Here they are, in terms of Transformers' checkpoint format. Link: [https://www.dropbox.com/sh/se991tx7cxm0aec/AAAFAuwr4NCLVDVqV26ZESmqa?dl=0](https://www.dropbox.com/sh/se991tx7cxm0aec/AAAFAuwr4NCLVDVqV26ZESmqa?dl=0)]


## Bibtex:
Please cite our paper, if you happen to use this codebase:

```
@ARTICLE{Zhang:TrojanLM
       author = {{Zhang}, Xinyang and {Zhang}, Zheng and {Ji}, Shouling and {Wang}, Ting},
        title = "{Trojaning Language Models for Fun and Profit}",
      journal = {arXiv e-prints},
         year = 2020,
        month = aug,
       eprint = {2008.00312},
 primaryClass = {cs.CR},
}
```